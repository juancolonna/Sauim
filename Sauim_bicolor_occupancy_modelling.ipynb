{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2012- Robert M Dorazio & J. Andrew Royle. Estimating Size and Composition of Biological Communities by Modeling the occurrence of Species.\n",
        "https://doi.org/10.1198/016214505000000015\n",
        "\n",
        "Zero-inflated model\n",
        "\n",
        "MacKenzie et al. 2006\n",
        "\n",
        "MacKenzie et al. 2002"
      ],
      "metadata": {
        "id": "-NMT6ojjDNlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "from joblib import dump, load\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Patch  # for legend patch\n",
        "from scipy.optimize import minimize_scalar\n",
        "from scipy.stats import norm, beta"
      ],
      "metadata": {
        "id": "eJDdUdOO8B_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the directory and all its contents\n",
        "if os.path.exists('MinduPark'):\n",
        "    shutil.rmtree('MinduPark')\n",
        "    print(\"Folder 'MinduPark' removed.\")\n",
        "if os.path.exists('MinduPark_without_sauim'):\n",
        "    shutil.rmtree('MinduPark_without_sauim')\n",
        "    print(\"Folder 'MinduPark_without_sauim' removed.\")"
      ],
      "metadata": {
        "id": "vmzplud6tGG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auxiliar funtions"
      ],
      "metadata": {
        "id": "TCed0ltCQCHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def w_mle_variance_ci(k, K, p11):\n",
        "    \"\"\"\n",
        "    Estima w_hat, Var(w_hat) e SE(w_hat)\n",
        "    no modelo q = w * p11, k ~ Bin(K, q).\n",
        "\n",
        "    Parâmetros:\n",
        "      k    : nº de sítios com ≥1 detecção\n",
        "      K    : nº total de sítios\n",
        "      p11  : prob. de detecção quando ocupado (fixa/conhecida)\n",
        "\n",
        "    Retorna:\n",
        "      dict com w_hat, var_wald, se_wald\n",
        "    \"\"\"\n",
        "    if not (0 <= k <= K):\n",
        "        raise ValueError(\"Exige 0 <= k <= K.\")\n",
        "    if not (0 < p11 <= 1):\n",
        "        raise ValueError(\"Exige 0 < p11 <= 1.\")\n",
        "\n",
        "    # MLE fechada\n",
        "    q_hat = k / K\n",
        "    w_hat = np.clip(q_hat / p11, 0.0, 1.0)\n",
        "\n",
        "    # Variância (delta-método) e SE\n",
        "    var_wald = (q_hat * (1 - q_hat)) / (K * (p11 ** 2))\n",
        "    se_wald = float(np.sqrt(max(var_wald, 0.0)))\n",
        "\n",
        "    return {\n",
        "        \"w_hat\": float(w_hat),\n",
        "        \"var_wald\": float(var_wald),\n",
        "        \"se_wald\": se_wald,\n",
        "    }"
      ],
      "metadata": {
        "id": "C8ktzC9lQEcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ocumpacy modeling"
      ],
      "metadata": {
        "id": "4n2bF-1Q2RcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eldke65Zhynt"
      },
      "source": [
        "Automatically download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/juancolonna/Sauim/raw/main/MinduPark.zip -O MinduPark.zip\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/MinduPark_without_sauim.zip -O MinduPark_without_sauim.zip\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/ocsvm_filtered.joblib -O ocsvm_filtered.joblib"
      ],
      "metadata": {
        "id": "uohHR9HvB1YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open and extract files\n",
        "with zipfile.ZipFile('MinduPark.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "with zipfile.ZipFile('MinduPark_without_sauim.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "print(f'Files extracted')"
      ],
      "metadata": {
        "id": "MNKAXX6TPe7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = load(\"ocsvm_filtered.joblib\")"
      ],
      "metadata": {
        "id": "KMW550l9s_tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = np.array([[179,0],[4,32]])\n",
        "\n",
        "# Fixed parameters\n",
        "p10 = cm[0,1]/cm.sum(axis=1)[0]  # prob. of \"false detection\"\n",
        "p11 = cm[1,1]/cm.sum(axis=1)[1]  # prob. of \"detection\"\n",
        "p01 = 1-p11\n",
        "p00 = 1-p10\n",
        "\n",
        "eps = 1e-10\n",
        "\n",
        "print(f\"p11:{p11}, p10:{p10}, p01:{p01}, p00:{p00}\")"
      ],
      "metadata": {
        "id": "XOBh6J1K4e49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semples monitoring with Sauim occurrences"
      ],
      "metadata": {
        "id": "h4vXcVURPsKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "T = []\n",
        "detections_per_record = []\n",
        "\n",
        "for i in range(8):\n",
        "    MinduPark_embedding_vectors = np.load(\"MinduPark/MinduPark_vectors_filtered_\"+str(i)+\".npy\")\n",
        "    decision_scores = clf.decision_function(MinduPark_embedding_vectors)\n",
        "    MinduPark_preds = np.where(decision_scores >= 0, 1, 0)\n",
        "    y.append(np.sum(MinduPark_preds == 1))\n",
        "    T.append(len(MinduPark_preds))\n",
        "    detections_per_record.append(MinduPark_preds)\n",
        "\n",
        "y = np.array(y)\n",
        "T = np.array(T)\n",
        "print(y) # How many detections per record\n",
        "print(T) # How many segments per record"
      ],
      "metadata": {
        "id": "p-mC1xbBevrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections = int(np.sum(y > 0))\n",
        "detections"
      ],
      "metadata": {
        "id": "XTEhfjzKScqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "K = len(y)\n",
        "mle_w = []\n",
        "logLike = []\n",
        "w_lo = []   # SE-based lower band for w\n",
        "w_hi = []   # SE-based upper band for w\n",
        "\n",
        "eps = 1e-12\n",
        "\n",
        "for k in range(len(y)+1):\n",
        "    def loglike(w):\n",
        "        if w <= 0 or w >= 1:\n",
        "            return -np.inf\n",
        "        q = np.clip(w * p11, eps, 1 - eps)\n",
        "        return k*np.log(q) + (K - k)*np.log(1 - q)\n",
        "\n",
        "    res = minimize_scalar(lambda w: -loglike(w), bounds=(0,1), method=\"bounded\")\n",
        "    w_hat_k = res.x\n",
        "    mle_w.append(w_hat_k)\n",
        "    logLike.append(-res.fun)\n",
        "\n",
        "    # ---- use SE_wald directly ----\n",
        "    stats_k = w_mle_variance_ci(k, K, p11)\n",
        "    se_k = stats_k[\"se_wald\"]\n",
        "\n",
        "    lo = np.clip(w_hat_k - se_k, 0.0, 1.0)\n",
        "    hi = np.clip(w_hat_k + se_k, 0.0, 1.0)\n",
        "\n",
        "    w_lo.append(lo)\n",
        "    w_hi.append(hi)\n",
        "\n",
        "detections = int(np.sum(y > 0))\n",
        "\n",
        "# --- plotting (unchanged except labels) ---\n",
        "fig, ax1 = plt.subplots()\n",
        "x = np.arange(len(mle_w))\n",
        "\n",
        "l1, = ax1.plot(x, mle_w, label=\"$\\\\psi$ (MLE)\")\n",
        "ax1.set_ylabel(\"$\\\\psi$ (MLE)\", color=\"blue\", fontsize=14)\n",
        "ax1.set_ylim(-0.01, 1.01)\n",
        "\n",
        "band = ax1.fill_between(x, w_lo, w_hi, alpha=0.2, color=l1.get_color())\n",
        "se_patch = Patch(facecolor=l1.get_color(), alpha=0.2, label=f\"±SE\")\n",
        "\n",
        "y_hat_at_det = mle_w[detections]\n",
        "lo_at_det = w_lo[detections]\n",
        "hi_at_det = w_hi[detections]\n",
        "yerr_det = np.array([[y_hat_at_det - lo_at_det], [hi_at_det - y_hat_at_det]])\n",
        "eb = ax1.errorbar([detections], [y_hat_at_det], yerr=yerr_det, fmt='o', color='black',\n",
        "                  capsize=3, label=\"detections\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "l2, = ax2.plot(x, logLike, label=\"log-like\", color=\"red\", linestyle=\"--\")\n",
        "ax2.set_ylabel(\"log-likelihood\", color=\"red\", fontsize=14)\n",
        "\n",
        "ax1.set_xlabel(\"Number of detections\", fontsize=14)\n",
        "lines = [l1, se_patch, l2, eb]\n",
        "labels = [ln.get_label() for ln in lines]\n",
        "ax1.legend(lines, labels, loc=\"lower right\")\n",
        "\n",
        "# tamanho dos números dos eixos (tiques)\n",
        "ax1.tick_params(axis='both', labelsize=14)  # x e y do ax1\n",
        "ax2.tick_params(axis='y', labelsize=14)     # y do ax2 (direita)\n",
        "\n",
        "fig.tight_layout()\n",
        "ax1.grid(True, axis='y', which='both')\n",
        "ax2.grid(False)\n",
        "ax2.patch.set_visible(False)\n",
        "ax1.set_axisbelow(True)\n",
        "\n",
        "plt.savefig(\"likelihood.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Am1gmDKvdItq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados agregados:\n",
        "k = int(np.sum(y > 0))   # nº de sítios com ≥1 detecção\n",
        "K = int(len(y))          # nº total de sítios\n",
        "eps = 1e-12              # p/ evitar log(0)\n",
        "\n",
        "def loglike(w):\n",
        "    if w <= 0 or w >= 1:\n",
        "        return -np.inf  # fora do domínio\n",
        "    q = w * p11\n",
        "    q = np.clip(q, eps, 1 - eps)\n",
        "    return k*np.log(q) + (K - k)*np.log(1 - q)\n",
        "\n",
        "# Minimiza o negativo do log-likelihood\n",
        "res = minimize_scalar(lambda w: -loglike(w), bounds=(eps, 1 - eps), method=\"bounded\")\n",
        "\n",
        "print(\"MLE estimate of w:\", res.x)\n",
        "print(\"Max log-likelihood:\", -res.fun)\n"
      ],
      "metadata": {
        "id": "PjzekrBj6CG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exemplo de uso ---\n",
        "# Suponha que você já tenha:\n",
        "k = int(np.sum(y > 0))\n",
        "K = int(len(y))\n",
        "\n",
        "res = w_mle_variance_ci(k, K, p11)\n",
        "print(\"ŵ:\", res[\"w_hat\"])\n",
        "print(\"Var (Wald):\", res[\"var_wald\"])\n",
        "print(\"SE (Wald):\", res[\"se_wald\"])"
      ],
      "metadata": {
        "id": "-ox1TQ2u7OPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Samples of monitoring without sauim occurrences"
      ],
      "metadata": {
        "id": "pmzHC8CgP2Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = []\n",
        "T = []\n",
        "detections_per_record = []\n",
        "\n",
        "for i in range(8):\n",
        "    MinduPark_embedding_vectors = np.load(\"MinduPark_without_sauim/MinduPark_vectors_filtered_\"+str(i)+\".npy\")\n",
        "    decision_scores = clf.decision_function(MinduPark_embedding_vectors)\n",
        "    MinduPark_preds = np.where(decision_scores >= 0, 1, 0)\n",
        "    y.append(np.sum(MinduPark_preds == 1))\n",
        "    T.append(len(MinduPark_preds))\n",
        "    detections_per_record.append(MinduPark_preds)\n",
        "\n",
        "y = np.array(y)\n",
        "T = np.array(T)\n",
        "print(y) # How many detections per record\n",
        "print(T) # How many segments per record"
      ],
      "metadata": {
        "id": "nLILAJHtP55m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Exemplo de uso ---\n",
        "k = int(np.sum(y > 0))\n",
        "K = int(len(y))\n",
        "\n",
        "res = w_mle_variance_ci(k, K, p11)\n",
        "print(\"ŵ:\", res[\"w_hat\"])\n",
        "print(\"Var (Wald):\", res[\"var_wald\"])\n",
        "print(\"SE (Wald):\", res[\"se_wald\"])"
      ],
      "metadata": {
        "id": "9-w5TTy1QMT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}