{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xs9HL70Co2Z"
      },
      "source": [
        "Refs:\n",
        "\n",
        "https://gpmainpa.wordpress.com/2021/06/17/o-sauim-de-maos-douradas-muda-sua-vocalizacao/\n",
        "\n",
        "https://www.kaggle.com/models/google/bird-vocalization-classifier\n",
        "\n",
        "https://research.google/blog/whistles-songs-boings-and-biotwangs-recognizing-whale-vocalizations-with-ai/\n",
        "\n",
        "https://research.google/blog/in-search-of-a-generalizable-method-for-source-free-domain-adaptation/\n",
        "\n",
        "https://github.com/google-research/perch/blob/main/embed_audio.ipynb\n",
        "\n",
        "https://arxiv.org/abs/2312.07439\n",
        "\n",
        "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=c72bb6c83db08e17e2736bc1d2cf439fe1f71905\n",
        "\n",
        "https://colab.research.google.com/github/climatechange-ai-tutorials/bioacoustic-monitoring/blob/main/Agile_Modeling_for_Bioacoustic_Monitoring.ipynb\n",
        "\n",
        "https://arxiv.org/pdf/2505.03071v4\n",
        "\n",
        "https://arxiv.org/pdf/2212.09058v1\n",
        "\n",
        "https://www.frontiersin.org/journals/bird-science/articles/10.3389/fbirs.2024.1380636/full\n",
        "\n",
        "https://arxiv.org/pdf/2508.04665v1\n",
        "\n",
        "file:///home/juan/Research/Articles/Ecological%20Informatics/2021%20-%20Applications%20of%20machine%20learning%20to%20ecological%20modelling.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Remove the directory and all its contents\n",
        "if os.path.exists('embedding_vectors'):\n",
        "    shutil.rmtree('embedding_vectors')\n",
        "    print(\"Folder 'embedding_vectors' removed.\")"
      ],
      "metadata": {
        "id": "eJDdUdOO8B_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXBASefWBZUK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import gdown\n",
        "import zipfile\n",
        "from math import log, exp, comb\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from joblib import dump, load\n",
        "from sklearn.svm import OneClassSVM\n",
        "from scipy.special import expit  # sigmoid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (make_scorer, f1_score, accuracy_score, confusion_matrix,\n",
        "                             roc_auc_score, roc_curve, auc, precision_score,\n",
        "                             recall_score, average_precision_score, precision_recall_curve)\n",
        "from sklearn.utils import shuffle\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler # for PCA\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d3oxrg1mlIJ"
      },
      "source": [
        "Auxiliar functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hlopgrd4rPJ"
      },
      "outputs": [],
      "source": [
        "def metrics_calculation(y_test, y_pred, decision_scores, label=\"Anomaly\"):\n",
        "\n",
        "    # print(f\"True Labels (0=label, 1=Sauim):\\n{y_test}\")\n",
        "    # print(f\"Predicted Labels (0=label, 1=Sauim):\\n{y_pred}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(4.2, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 18},  cbar=False,\n",
        "                xticklabels=[label, 'Sauim'], yticklabels=[label, 'Sauim'])\n",
        "    # plt.ylabel('Actual Label', fontsize=18)\n",
        "    # plt.xlabel('Predicted Label', fontsize=18)\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)  # rotation=0 keeps them horizontal\n",
        "    # plt.title(label, fontsize=20)\n",
        "    plt.savefig(\"ConfusionMatrix_\"+label+\".pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred) # Accuracy (may be misleading with imbalanced data)\n",
        "    f1 = f1_score(y_test, y_pred, pos_label=1, average='weighted') # F1-score for the 'sauim' class (positive class)\n",
        "\n",
        "    # Precision and Recall\n",
        "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "    # ROC AUC Curve (useful if you want to choose a threshold based on decision_function)\n",
        "    # For ROC AUC, 1 represents the positive class (sauim)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, decision_scores, pos_label=1)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"Acc: {accuracy:.2f}, Prec: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}, roc_auc: {roc_auc:.2f}\")\n",
        "    return fpr, tpr, roc_auc, cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eldke65Zhynt"
      },
      "source": [
        "Automatically download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/juancolonna/Sauim/raw/main/embedding_vectors.zip -O embedding_vectors.zip\n",
        "\n",
        "# Open and extract files\n",
        "with zipfile.ZipFile('embedding_vectors.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "print(f'Files extracted')\n",
        "\n",
        "filtered_files = True\n",
        "\n",
        "if filtered_files:\n",
        "    sauim_vectors = np.load('embedding_vectors/sauim_vectors_filtered.npy')\n",
        "    anurans_vectors = np.load('embedding_vectors/anurans_vectors_filtered.npy')\n",
        "    background_vectors = np.load('embedding_vectors/background_vectors_filtered.npy')\n",
        "    birds_vectors = np.load('embedding_vectors/birds_vectors_filtered.npy')\n",
        "    anthrophony_vectors = np.load('embedding_vectors/anthrophony_vectors_filtered.npy')\n",
        "    geophony_vectors = np.load('embedding_vectors/geophony_vectors_filtered.npy')\n",
        "else:\n",
        "    sauim_vectors = np.load('embedding_vectors/sauim_vectors.npy')\n",
        "    anurans_vectors = np.load('embedding_vectors/anurans_vectors.npy')\n",
        "    background_vectors = np.load('embedding_vectors/background_vectors.npy')\n",
        "    birds_vectors = np.load('embedding_vectors/birds_vectors.npy')\n",
        "    anthrophony_vectors = np.load('embedding_vectors/anthrophony_vectors.npy')\n",
        "    geophony_vectors = np.load('embedding_vectors/geophony_vectors.npy')"
      ],
      "metadata": {
        "id": "lVOUROvTasEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm-F9SsRr3ZC"
      },
      "outputs": [],
      "source": [
        "sr = 32000\n",
        "window_len = int(5*sr)\n",
        "step = 1\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vaa5Hx4-wFM"
      },
      "source": [
        "One-class classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVas_jqKp6_d"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(sauim_vectors)\n",
        "\n",
        "# For this example, we'll train on the 'normal_data'\n",
        "X_train_normal, X_test_normal = train_test_split(X_train, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create labels\n",
        "X_test_background_combined = np.concatenate([X_test_normal, background_vectors])\n",
        "\n",
        "# Create labels, 1 means normal data (sauim)\n",
        "y_train_normal = np.ones(X_train_normal.shape[0]).astype(int)\n",
        "y_test_normal = np.ones(X_test_normal.shape[0]).astype(int)\n",
        "\n",
        "y_test_background_combined = np.concatenate([y_test_normal, np.zeros(background_vectors.shape[0])]).astype(int)\n",
        "\n",
        "print(f\"Shape of X_train_normal (used for fitting): {X_train_normal.shape}\")\n",
        "print(f\"Shape of X_test_normal (part of test set): {X_test_normal.shape}\")\n",
        "print(f\"Shape of X_test_combined (combined test set): {X_test_background_combined.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYZLfT08wQMs"
      },
      "source": [
        "One-class classifier train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDZSJk_0EBta"
      },
      "outputs": [],
      "source": [
        "# --- 3. Instantiate the One-Class SVM Model ---\n",
        "# Key parameters:\n",
        "#   nu: An upper bound on the fraction of training errors (outliers) and a lower\n",
        "#       bound of the fraction of support vectors.\n",
        "#       A common range is 0.01 to 0.1.\n",
        "#   kernel: 'rbf'\n",
        "#   gamma: 'auto' is `1 / n_features`\n",
        "# nu with filter 0.022, 0.0345\n",
        "# nu without filter 0.07\n",
        "\n",
        "# Save the fitted model\n",
        "if filtered_files:\n",
        "    clf = OneClassSVM(kernel='rbf', nu=0.022, gamma='auto') # We might need to tune this with GridSearchCV/RandomizedSearchCV if performance isn't good.\n",
        "    clf.fit(X_train_normal)\n",
        "    dump(clf, \"ocsvm_filtered.joblib\")\n",
        "else:\n",
        "    clf = OneClassSVM(kernel='rbf', nu=0.07, gamma='auto') # We might need to tune this with GridSearchCV/RandomizedSearchCV if performance isn't good.\n",
        "    clf.fit(X_train_normal)\n",
        "    dump(clf, \"ocsvm.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYZsFyTYEGiV"
      },
      "source": [
        "## Score on background noise\n",
        "\n",
        "The .predict() method returns -1 for outliers/anomalies and 1 for inliers/normal points.\n",
        "\n",
        "The .decision_function() method returns the signed distance to the hyperplane.\n",
        "\n",
        "Positive values indicate inliers, negative values indicate outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvVBZYe3dMic"
      },
      "outputs": [],
      "source": [
        "predictions = clf.predict(X_test_background_combined)\n",
        "decision_scores = clf.decision_function(X_test_background_combined)\n",
        "\n",
        "# Convert predictions to 0 for normal, 1 for anomaly to match y_true_combined\n",
        "# Note: OCSVM predicts 1 for inliers (normal) and -1 for outliers (anomalies)\n",
        "# So, we map 1 -> 1 and -1 -> 0\n",
        "y_pred = np.where(predictions == -1, 0, 1)\n",
        "\n",
        "# --- 6. Evaluate the Model ---\n",
        "fpr1, tpr1, roc_auc_background, cm1 = metrics_calculation(y_test_background_combined,\n",
        "                                                          y_pred,\n",
        "                                                          decision_scores,\n",
        "                                                          label=\"Background\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W-RSnJW5v5r"
      },
      "source": [
        "Permutation Importance (global)\n",
        "Avalia a queda de desempenho quando embaralha cada feature. Fácil, rápido e robusto.\n",
        "\n",
        "O que medir? Use AUC-ROC/PR sobre y_test_combined usando -decision_function(X) (maior = mais anômalo).\n",
        "\n",
        "Prós: Simples, interpreta globalmente.\n",
        "\n",
        "Contras: Requer rótulos (mesmo que sintéticos) e é global (não explica um ponto específico)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2puP1wBI01cc"
      },
      "outputs": [],
      "source": [
        "# def anomaly_score(X):  # maior = mais anômalo\n",
        "#     return (clf.decision_function(X)).ravel()\n",
        "\n",
        "# base_scores = anomaly_score(X_test_background_combined)\n",
        "# base_auc = roc_auc_score(y_test_background_combined, base_scores)\n",
        "\n",
        "# print(f\"Baseline AUC: {base_auc:.2f}\")\n",
        "\n",
        "# rng = np.random.RandomState(42)\n",
        "# n_repeats = 10\n",
        "# importances = []\n",
        "\n",
        "# for j in range(X_test_background_combined.shape[1]):\n",
        "#     auc_drops = []\n",
        "#     for _ in range(n_repeats):\n",
        "#         Xp = X_test_background_combined.copy()\n",
        "#         Xp[:, j] = shuffle(Xp[:, j], random_state=rng)\n",
        "#         auc_p = roc_auc_score(y_test_background_combined, anomaly_score(Xp))\n",
        "#         auc_drops.append(base_auc - auc_p)\n",
        "#     importances.append(np.mean(auc_drops))\n",
        "\n",
        "# importances = np.array(importances)\n",
        "# rank = np.argsort(importances)[::-1]\n",
        "# for k in rank[:10]:\n",
        "#     print(f\"feat {k}: ΔAUC = {importances[k]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8647I1b4_JcY"
      },
      "source": [
        "## Anuran comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-5OJZIX8l7t"
      },
      "outputs": [],
      "source": [
        "# X_test_anuran_anomaly = np.array(anurans_embedding_vectors)\n",
        "X_test_anuran_combined = np.concatenate([X_test_normal, anurans_vectors])\n",
        "y_test_anuran_anomaly = np.zeros(anurans_vectors.shape[0]).astype(int)\n",
        "y_test_anuran_combined = np.concatenate([y_test_normal, y_test_anuran_anomaly]).astype(int)\n",
        "\n",
        "print(f\"Shape of X_test_anuran_combined (combined test set): {X_test_anuran_combined.shape}\")\n",
        "\n",
        "predictions = clf.predict(X_test_anuran_combined)\n",
        "decision_scores = clf.decision_function(X_test_anuran_combined)\n",
        "\n",
        "y_pred = np.where(predictions == -1, 0, 1)\n",
        "\n",
        "fpr2, tpr2, roc_auc_anuran, cm2 = metrics_calculation(y_test_anuran_combined, y_pred,\n",
        "                                               decision_scores,\n",
        "                                               label=\"Anurans\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6FJ5AfLBRWt"
      },
      "source": [
        "## bird comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjah8O-QBRq6"
      },
      "outputs": [],
      "source": [
        "X_test_birds_combined = np.concatenate([X_test_normal, birds_vectors])\n",
        "y_test_birds_anomaly = np.zeros(birds_vectors.shape[0]).astype(int)\n",
        "y_test_birds_combined = np.concatenate([y_test_normal, y_test_birds_anomaly]).astype(int)\n",
        "\n",
        "print(f\"Shape of X_test_birds_combined (combined test set): {X_test_birds_combined.shape}\")\n",
        "\n",
        "predictions = clf.predict(X_test_birds_combined)\n",
        "decision_scores = clf.decision_function(X_test_birds_combined)\n",
        "\n",
        "y_pred = np.where(predictions == -1, 0, 1)\n",
        "\n",
        "fpr3, tpr3, roc_auc_birds, cm3 = metrics_calculation(y_test_birds_combined, y_pred,\n",
        "                                               decision_scores,\n",
        "                                               label=\"Birds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anthrophony"
      ],
      "metadata": {
        "id": "Mqy6EVdddeQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_anthrophony_combined = np.concatenate([X_test_normal, anthrophony_vectors])\n",
        "y_test_anthrophony_anomaly = np.zeros(anthrophony_vectors.shape[0]).astype(int)\n",
        "y_test_anthrophony_combined = np.concatenate([y_test_normal, y_test_anthrophony_anomaly]).astype(int)\n",
        "\n",
        "print(f\"Shape of X_test_anthrophony_combined (combined test set): {X_test_anthrophony_combined.shape}\")\n",
        "\n",
        "predictions = clf.predict(X_test_anthrophony_combined)\n",
        "decision_scores = clf.decision_function(X_test_anthrophony_combined)\n",
        "\n",
        "y_pred = np.where(predictions == -1, 0, 1)\n",
        "\n",
        "fpr4, tpr4, roc_auc_anthrophony, cm4 = metrics_calculation(y_test_anthrophony_combined, y_pred,\n",
        "                                               decision_scores,\n",
        "                                               label=\"Anthrophony\")"
      ],
      "metadata": {
        "id": "rycdivDYdd0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geophony"
      ],
      "metadata": {
        "id": "lCWUqVU8d7C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_geophony_combined = np.concatenate([X_test_normal, geophony_vectors])\n",
        "y_test_geophony_anomaly = np.zeros(geophony_vectors.shape[0]).astype(int)\n",
        "y_test_geophony_combined = np.concatenate([y_test_normal, y_test_geophony_anomaly]).astype(int)\n",
        "\n",
        "print(f\"Shape of X_test_geophony_combined (combined test set): {X_test_geophony_combined.shape}\")\n",
        "\n",
        "predictions = clf.predict(X_test_geophony_combined)\n",
        "decision_scores = clf.decision_function(X_test_geophony_combined)\n",
        "\n",
        "y_pred = np.where(predictions == -1, 0, 1)\n",
        "\n",
        "fpr5, tpr5, roc_auc_geophony, cm5 = metrics_calculation(y_test_geophony_combined, y_pred,\n",
        "                                               decision_scores,\n",
        "                                               label=\"Geophony\")"
      ],
      "metadata": {
        "id": "X53Oh8Iwd6TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk_Hgb4vEYII"
      },
      "source": [
        "## Comparison all datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(5.4, 5))\n",
        "# plt.plot(fpr1, tpr1, lw=1.5, label='Background (AUC = %0.2f)' % roc_auc_background)\n",
        "# plt.plot(fpr2, tpr2, lw=1.5, label='Anurans (AUC = %0.2f)' % roc_auc_anuran)\n",
        "# plt.plot(fpr3, tpr3, lw=1.5, label='Birds (AUC = %0.2f)' % roc_auc_birds)\n",
        "# plt.plot(fpr4, tpr4, lw=1.5, label='Anthrophony (AUC = %0.2f)' % roc_auc_anthrophony)\n",
        "# plt.plot(fpr4, tpr4, lw=1.5, label='Geophony (AUC = %0.2f)' % roc_auc_geophony)\n",
        "# plt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--')\n",
        "# plt.xlim([-0.01, 1.0])\n",
        "# plt.ylim([0.0, 1.01])\n",
        "# plt.legend(loc=\"lower right\", fontsize=10)\n",
        "# plt.ylabel('True Positive Rate', fontsize=12)\n",
        "# plt.xlabel('False Positive Rate', fontsize=12)\n",
        "# plt.xticks(fontsize=12)\n",
        "# plt.yticks(fontsize=12)  # rotation=0 keeps them horizontal\n",
        "# plt.grid(True, linestyle='--', alpha=0.7)\n",
        "# plt.savefig(\"ROC_curves.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "5OlfxmvzCqf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5.4, 5))\n",
        "\n",
        "# --- curvas principais ---\n",
        "ax.plot(fpr1, tpr1, lw=1.5, label=f'Background (AUC = {roc_auc_background:0.2f})')\n",
        "ax.plot(fpr2, tpr2, lw=1.5, label=f'Anurans (AUC = {roc_auc_anuran:0.2f})')\n",
        "ax.plot(fpr3, tpr3, lw=1.5, label=f'Birds (AUC = {roc_auc_birds:0.2f})')\n",
        "ax.plot(fpr4, tpr4, lw=1.5, label=f'Anthrophony (AUC = {roc_auc_anthrophony:0.2f})')\n",
        "ax.plot(fpr5, tpr5, lw=1.5, label=f'Geophony (AUC = {roc_auc_geophony:0.2f})')  # <-- use fpr5/tpr5 se for outra curva\n",
        "ax.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--')\n",
        "\n",
        "ax.set_xlim(-0.01, 1.0)\n",
        "ax.set_ylim(0.0, 1.01)\n",
        "ax.legend(loc=\"lower right\", fontsize=10)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax.tick_params(labelsize=12)\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "ax.set_axisbelow(True)  # grid atrás das linhas\n",
        "\n",
        "# --- inset (zoom) ---\n",
        "# Inset posicionado no topo central\n",
        "axins = zoomed_inset_axes(ax, zoom=3.5, loc='upper center', borderpad=1.0)\n",
        "axins.set_facecolor('none')  # evita \"lavar\" o gráfico principal\n",
        "ax.grid(alpha=0.4)\n",
        "# Replote as MESMAS curvas dentro do inset\n",
        "axins.plot(fpr1, tpr1, lw=1.2)\n",
        "axins.plot(fpr2, tpr2, lw=1.2)\n",
        "axins.plot(fpr3, tpr3, lw=1.2)\n",
        "axins.plot(fpr4, tpr4, lw=1.2)\n",
        "axins.plot(fpr5, tpr5, lw=1.2)\n",
        "axins.plot([0, 1], [0, 1], lw=1.0, linestyle='--')\n",
        "\n",
        "# Defina a região a \"dar zoom\": canto superior direito (FPR ~1, TPR ~1)\n",
        "x1, x2 = -0.01, 0.07   # ajuste conforme seu dado\n",
        "y1, y2 = 0.93, 1.01\n",
        "axins.set_xlim(x1, x2)\n",
        "axins.set_ylim(y1, y2)\n",
        "\n",
        "# Aparência do inset\n",
        "axins.grid(False)\n",
        "axins.tick_params(labelsize=9)\n",
        "axins.set_xticklabels([])\n",
        "axins.set_yticklabels([])\n",
        "\n",
        "# Conecte o retângulo de zoom ao gráfico principal\n",
        "# use cantos direitos do inset para linhas (1=UR, 4=LR)\n",
        "mark_inset(ax, axins, loc1=2, loc2=3, fc=\"none\", ec=\"0.5\", lw=1.5, linestyle='--')\n",
        "\n",
        "plt.savefig(\"ROC_curves_filtered.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LoqJPfmq0VMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vfVCn1F03Ql"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vuGSHnp7LWK"
      },
      "outputs": [],
      "source": [
        "data_points = np.concatenate([X_train,\n",
        "                              background_vectors,\n",
        "                              anurans_vectors,\n",
        "                              birds_vectors,\n",
        "                              anthrophony_vectors,\n",
        "                              geophony_vectors])\n",
        "m = X_train.shape[0]\n",
        "n = background_vectors.shape[0]\n",
        "p = anurans_vectors.shape[0]\n",
        "q = birds_vectors.shape[0]\n",
        "r = anthrophony_vectors.shape[0]\n",
        "s = geophony_vectors.shape[0]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_points_scaled = scaler.fit_transform(data_points)\n",
        "\n",
        "pca = PCA(n_components=2) # Reduzir para 2 componentes para plotagem 2D\n",
        "X_train_pca = pca.fit_transform(data_points_scaled) # Ajustar e transformar\n",
        "\n",
        "plt.figure(figsize=(10, 8), dpi=100)\n",
        "sns.set_style(\"whitegrid\") # Um estilo de plotagem agradável\n",
        "\n",
        "# Plotar os dados de treino normais\n",
        "plt.scatter(X_train_pca[0:m, 0], X_train_pca[0:m, 1],\n",
        "            label='Sauim calls', alpha=0.8, s=50, color='blue', edgecolor='w')\n",
        "\n",
        "# Plotar os dados de anomalia\n",
        "plt.scatter(X_train_pca[m:n+m, 0], X_train_pca[m:n+m, 1],\n",
        "            label='Background forest', alpha=0.6, s=100, color='red', marker='X', edgecolor='black')\n",
        "\n",
        "plt.scatter(X_train_pca[m+n:n+m+p, 0], X_train_pca[m+n:n+m+p, 1],\n",
        "            label='Anurans', alpha=0.6, s=100, color='green', marker='*', edgecolor='black')\n",
        "\n",
        "plt.scatter(X_train_pca[m+n+p:n+m+p+q, 0], X_train_pca[m+n+p:n+m+p+q, 1],\n",
        "            label='Birds', alpha=0.6, s=60, color='black', marker='o', edgecolor='black')\n",
        "\n",
        "plt.scatter(X_train_pca[m+n+p+q:n+m+p+q+r, 0], X_train_pca[m+n+p+q:n+m+p+q+r, 1],\n",
        "            label='Anthrophony', alpha=0.6, s=60, color='orange', marker='.', edgecolor='black')\n",
        "\n",
        "plt.scatter(X_train_pca[m+n+p+q+r:n+m+p+q+r+s, 0], X_train_pca[m+n+p+q+r:n+m+p+q+r+s, 1],\n",
        "            label='Geophony', alpha=0.6, s=60, color='pink', marker='^', edgecolor='black')\n",
        "\n",
        "plt.xlabel(f'PC 1 (explained variance ratio {pca.explained_variance_ratio_[0]*100:.2f}%)',fontsize=18)\n",
        "plt.ylabel(f'PC 2 (explained variance ratio {pca.explained_variance_ratio_[1]*100:.2f}%)',fontsize=18)\n",
        "plt.legend(loc='lower right' , fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.axhline(0, color='gray', linewidth=0.8)\n",
        "plt.axvline(0, color='gray', linewidth=0.8)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)  # rotation=0 keeps them horizontal\n",
        "plt.savefig(\"PCA_filtered.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# --- Informações adicionais do PCA ---\n",
        "print(\"Variância explicada por cada componente principal:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(f\"Variância acumulada explicada pelas 2 primeiras componentes: {pca.explained_variance_ratio_.sum()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrH7v30lzqVL"
      },
      "source": [
        "*   inside normal region (f(x) > 0)\n",
        "*   on boundary (f(x) == 0)\n",
        "*   outside/anomaly (f(x) < 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "Z = clf.decision_function(X_train)\n",
        "X_pca = pca.transform(X_train)\n",
        "\n",
        "# Labels: 1 = inside, 0 = boundary, -1 = outside\n",
        "labels = np.where(Z > 0, 1, np.where(Z < 0, -1, 0))\n",
        "\n",
        "# Define 3 colors: [-1, 0, 1] -> [red, black, green]\n",
        "cmap = ListedColormap(['red', 'black', 'green'])\n",
        "color_index = labels + 1  # -1→0, 0→1, 1→2\n",
        "\n",
        "print(f\"Outliers: {np.sum(labels == -1)}\")\n",
        "\n",
        "plt.figure(figsize=(10, 8), dpi=100)\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=color_index, cmap=cmap, s=60, edgecolor='k')\n",
        "\n",
        "# Add sample numbers for outliers (red points, label == -1)\n",
        "for i, (x, y, lbl) in enumerate(zip(X_pca[:, 0], X_pca[:, 1], labels)):\n",
        "    if lbl == -1:  # outlier\n",
        "        print(i)\n",
        "        plt.text(x + 0.01, y + 0.01, str(i), fontsize=12, color='darkred')\n",
        "\n",
        "plt.xlabel(\"PCA 1\",fontsize=18)\n",
        "plt.ylabel(\"PCA 2\",fontsize=18)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "\n",
        "# ---- Legend em vez de título ----\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], marker='o', color='w', label='Outlier',\n",
        "           markerfacecolor='red', markeredgecolor='k', markersize=8),\n",
        "    Line2D([0], [0], marker='o', color='w', label='Normal',\n",
        "           markerfacecolor='green', markeredgecolor='k', markersize=8),\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='best', frameon=True, fontsize=14)\n",
        "\n",
        "# (removido) plt.title(\"One-Class SVM regions: red=outlier, black=boundary, green=normal\")\n",
        "\n",
        "plt.savefig(\"PCA_detections_filtered.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xYkYZjHkseuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDbIu09bvznF"
      },
      "outputs": [],
      "source": [
        "# for i in [i/10000 for i in range(100, 510)]:\n",
        "#     clf = OneClassSVM(kernel='rbf', nu=i, gamma='auto') # We might need to tune this with GridSearchCV/RandomizedSearchCV if performance isn't good.\n",
        "#     clf.fit(X_train_normal)\n",
        "\n",
        "#     Z = clf.decision_function(X_train)\n",
        "#     X_pca = pca.transform(X_train)\n",
        "\n",
        "#     # Labels: 1 = inside, 0 = boundary, -1 = outside\n",
        "#     labels = np.where(Z > 0, 1, np.where(Z < 0, -1, 0))\n",
        "\n",
        "#     # Define 3 colors: inside, boundary, outside\n",
        "#     # For example: green (inside), black (boundary), red (outside)\n",
        "#     cmap = ListedColormap(['red', 'black', 'green'])  # order matches [-1, 0, 1]\n",
        "\n",
        "#     # Map labels to index in the colormap\n",
        "#     color_index = labels + 1  # so: -1 → 0, 0 → 1, 1 → 2\n",
        "#     print(f\"i:{i}\\t Outliers: {np.sum(labels == -1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uWw76cSazM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}