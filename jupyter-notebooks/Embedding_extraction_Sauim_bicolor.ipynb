{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1410e1a9"
      },
      "source": [
        "# Sauim bicolor Vocalization Classifier and Analysis\n",
        "\n",
        "This notebook demonstrates how to use the Perch bird vocalization classifier model from TensorFlow Hub to extract embeddings from audio files of Sauim bicolor primate and perform analysis on the extracted embeddings, such as hierarchical clustering.\n",
        "\n",
        "The notebook covers the following steps:\n",
        "\n",
        "1.  **Setup**: Installing necessary libraries and loading the Perch model.\n",
        "2.  **Data Loading**: Downloading example audio files and a CSV file containing labels.\n",
        "3.  **Feature Extraction**: Defining and using a function to extract embeddings and spectrograms from audio segments.\n",
        "4.  **Spectrogram Visualization**: Plotting spectrograms to visualize the audio data.\n",
        "5.  **Clustering Analysis**: Performing hierarchical clustering on the extracted embeddings and visualizing the results as a dendrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wn6WnFmiZMd"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow_hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXBASefWBZUK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import librosa\n",
        "import gdown\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import soundfile as sf\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "tf.experimental.numpy.experimental_enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgXzxtgeTZJv"
      },
      "outputs": [],
      "source": [
        "# Remove the directory and all its contents\n",
        "if os.path.exists('embedding_vectors'):\n",
        "    shutil.rmtree('embedding_vectors')\n",
        "    print(\"Folder 'embedding_vectors' removed.\")\n",
        "\n",
        "if os.path.exists('Parque do Mindú'):\n",
        "    shutil.rmtree('Parque do Mindú')\n",
        "    print(\"Folder 'Parque do Mindú' removed.\")\n",
        "\n",
        "if os.path.exists('MinduPark_38'):\n",
        "    shutil.rmtree('MinduPark_38')\n",
        "    print(\"Folder 'MinduPark_38' removed.\")\n",
        "\n",
        "if os.path.exists('Parque_do_Mindu_without_Sauim'):\n",
        "    shutil.rmtree('Parque_do_Mindu_without_Sauim')\n",
        "    print(\"Folder 'Parque_do_Mindu_without_Sauim' removed.\")\n",
        "\n",
        "if os.path.exists('model'):\n",
        "    shutil.rmtree('model')\n",
        "    print(\"Folder 'model' removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eldke65Zhynt"
      },
      "source": [
        "Automatically download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77UP_r_ERni-"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/records.csv -O records.csv\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Sauim.wav -O Sauim.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Anurans.wav -O Anurans.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Anthrophony.wav -O Anthrophony.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Background.wav -O Background.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Birds.wav -O Birds.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Geophony.wav -O Geophony.wav\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Mindu_Saguinus%20bicolor_02.02.19-000.wav -O Mindu_Saguinus_bicolor_02.02.19-000.wav\n",
        "\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Parque_do_Mindú.zip -O Parque_do_Mindú.zip\n",
        "!unzip -q Parque_do_Mindú.zip\n",
        "\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/records/Parque_do_Mindu_38.zip -O Parque_do_Mindu_38.zip\n",
        "!unzip -q Parque_do_Mindu_38.zip -d Parque_do_Mindu_38\n",
        "\n",
        "!wget https://github.com/juancolonna/Sauim/raw/main/perch_v8.zip -O perch_v8.zip\n",
        "!unzip -o perch_v8.zip -d ./model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is preferible to load the frozen model from github as follow\n",
        "model = hub.load(\"./model\")  # path containing saved_model.pb\n",
        "\n",
        "# If it presents any error you can load Perch model from kaggle as follow:\n",
        "# model = hub.load('https://www.kaggle.com/models/google/bird-vocalization-classifier/TensorFlow2/bird-vocalization-classifier/8')"
      ],
      "metadata": {
        "id": "bgUVwYmQZn-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7tEn_X7rJEy"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(file: str, wlen: int, hop_len: int, bandpass_filter: bool):\n",
        "    \"\"\"\n",
        "    Extracts embedding vectors and spectrograms from an audio file.\n",
        "\n",
        "    Args:\n",
        "        file (str): Path to the audio file.\n",
        "        wlen (int): Window length in samples.\n",
        "        hop_len (int): Hop length in samples.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (list of embedding vectors, list of spectrogram arrays)\n",
        "\n",
        "    Example:\n",
        "        >>> sr = 32000  # Sampling rate in Hz\n",
        "        >>> window_len = int(5 * sr)  # 5-second window\n",
        "        >>> emb, specs = extract_embeddings('Sauim.wav', wlen=window_len, hop_len=window_len)\n",
        "        >>> np.save('sauim_embedding_vectors.npy', emb)\n",
        "        >>> np.save('sauim_spectrograms.npy', specs)\n",
        "    \"\"\"\n",
        "\n",
        "    y, sr = librosa.load(file, sr=32000)  # Load audio\n",
        "    y = y / np.max(np.abs(y)) # Normalize amplitude\n",
        "\n",
        "    if bandpass_filter:\n",
        "        # 2) Design a band-pass Butterworth (4th order). Nyquist = fs/2, SciPy handles normalization with fs=\n",
        "        sos = signal.butter(N=4, Wn=[5000.0, 10000.0], btype=\"bandpass\", fs=sr, output=\"sos\")\n",
        "        # 3) Zero-phase filtering (filtfilt) along the time axis (axis=0 for (samples, channels))\n",
        "        y = signal.sosfiltfilt(sos, y.astype(np.float32), axis=0)\n",
        "        wavfile.write(file[:-4]+'_filtered.wav', sr, y.astype(np.float32))\n",
        "\n",
        "    embedding_vectors = []\n",
        "    spectrograms = []\n",
        "\n",
        "    for time in tqdm(range(0, len(y), hop_len)):\n",
        "        if time + wlen < len(y):\n",
        "            segment = y[time:time+wlen]\n",
        "            model_outputs = model.infer_tf(segment[np.newaxis, :])\n",
        "            embedding_vectors.append(model_outputs['embedding'].numpy()[0])\n",
        "            spectrograms.append(model_outputs['frontend'][0].T.numpy())\n",
        "\n",
        "    return embedding_vectors, spectrograms\n",
        "\n",
        "def plot_spectrogram(species: str, spectrograms):\n",
        "    \"\"\"\n",
        "    Plots a Mel spectrogram in dB scale for a given species.\n",
        "\n",
        "    Args:\n",
        "        species (str): Species name.\n",
        "        spectrograms (ndarray): Spectrogram array.\n",
        "        sr (int): Sampling rate in Hz.\n",
        "\n",
        "    Example:\n",
        "        >>> sr = 32000\n",
        "        >>> window_len = int(5 * sr)\n",
        "        >>> emb, specs = extract_embeddings('Sauim.wav', wlen=window_len, hop_len=window_len)\n",
        "        >>> # Plot the first extracted spectrogram\n",
        "        >>> plot_spectrogram(\"Saguinus bicolor\", specs[0], sr)\n",
        "    \"\"\"\n",
        "    S_dB = librosa.power_to_db(spectrograms, ref=np.max) # Convert to decibels\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    librosa.display.specshow(S_dB, sr=32000, x_axis='time', y_axis='mel',\n",
        "                            hop_length=256+64, # Provide hop_length for correct time axis\n",
        "                            cmap='viridis') # Ensure origin is lower for standard freq plot\n",
        "\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(f'Spectrogram of a 5-second segment of {species}')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Mel Frequency (Hz)') # Librosa will automatically format this as Mel-Hz\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys8WDZwRh0tI"
      },
      "source": [
        "Extract embeddings and spectrograms for a 'Sauim.wav' audio file and save them as NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-ju5lFYQ3P_"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"embedding_vectors\", exist_ok=True)  # cria se não existir\n",
        "\n",
        "sr = 32000 # Sampling rate (Hz)\n",
        "window_len = int(5*sr) # 5-second window length in samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm-F9SsRr3ZC"
      },
      "outputs": [],
      "source": [
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "sauim_vectors, sauim_spectrograms = extract_embeddings('Sauim.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/sauim_vectors.npy', sauim_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "sauim_vectors_filtered, _ = extract_embeddings('Sauim.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/sauim_vectors_filtered.npy', sauim_vectors_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZRKSsrIEafl"
      },
      "source": [
        "Background noise segments for anomaly data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeU1P_X9Ee8p"
      },
      "outputs": [],
      "source": [
        "background_vectors, background_spectrograms = extract_embeddings('Background.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                           bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/background_vectors.npy', background_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "background_vectors_filtered, _ = extract_embeddings('Background.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/background_vectors_filtered.npy', background_vectors_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9-9MDDNio92"
      },
      "source": [
        "Anuran calls used as negative class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjOyTxvd1LWm"
      },
      "outputs": [],
      "source": [
        "anurans_vectors, anurans_spectrograms = extract_embeddings('Anurans.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=int(window_len/2),\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/anurans_vectors.npy', anurans_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "anurans_vectors_filtered, _ = extract_embeddings('Anurans.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=int(window_len/2),\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/anurans_vectors_filtered.npy', anurans_vectors_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pEEIpn4it96"
      },
      "source": [
        "Bird calls used as negative class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1hMlnxB1pgc"
      },
      "outputs": [],
      "source": [
        "birds_vectors, birds_spectrograms = extract_embeddings('Birds.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/birds_vectors.npy', birds_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "birds_vectors_filtered, _ = extract_embeddings('Birds.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=window_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/birds_vectors_filtered.npy', birds_vectors_filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFrJH-nYixvX"
      },
      "source": [
        "A soundscape record used for new sauim detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMvhKXM6e37k"
      },
      "outputs": [],
      "source": [
        "step = 1\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "soundscape_vectors, soundscape_spectrograms = extract_embeddings('Mindu_Saguinus_bicolor_02.02.19-000.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/soundscape_vectors.npy', soundscape_vectors)\n",
        "\n",
        "soundscape_vectors_filtered, soundscape_spectrograms_filtered = extract_embeddings('Mindu_Saguinus_bicolor_02.02.19-000.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "np.save('embedding_vectors/soundscape_vectors_filtered.npy', soundscape_vectors_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b0iAEKoQqMf"
      },
      "outputs": [],
      "source": [
        "step = 2\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "anthrophony_vectors, anthrophony_spectrograms = extract_embeddings('Anthrophony.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/anthrophony_vectors.npy', anthrophony_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "anthrophony_vectors_filtered, _ = extract_embeddings('Anthrophony.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/anthrophony_vectors_filtered.npy', anthrophony_vectors_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lxIKJ3CX_K1"
      },
      "outputs": [],
      "source": [
        "step = 2\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "geophony_vectors, geophony_spectrograms = extract_embeddings('Geophony.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=False)\n",
        "\n",
        "np.save('embedding_vectors/geophony_vectors.npy', geophony_vectors)\n",
        "\n",
        "# Extract embeddings and spectrograms for each 5-second segment\n",
        "geophony_vectors_filtered, _ = extract_embeddings('Geophony.wav',\n",
        "                                                     wlen=window_len,\n",
        "                                                     hop_len=hop_len,\n",
        "                                                     bandpass_filter=True)\n",
        "\n",
        "# Save outputs to .npy files\n",
        "np.save('embedding_vectors/geophony_vectors_filtered.npy', geophony_vectors_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrlSkCc55kYM"
      },
      "outputs": [],
      "source": [
        "!zip -r embedding_vectors.zip embedding_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIBLVNOKVzf4"
      },
      "source": [
        "## Audio files for the Ocupancy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYc1IsuYUysm"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"MinduPark\", exist_ok=True)  # cria se não existir\n",
        "\n",
        "step = 2\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "for i, file in enumerate(os.listdir('Parque do Mindú')):\n",
        "    MinduPark_vectors, _ = extract_embeddings(\"Parque do Mindú/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=False)\n",
        "\n",
        "    np.save('MinduPark/MinduPark_vectors_'+str(i)+'.npy', MinduPark_vectors)\n",
        "\n",
        "    MinduPark_vectors_filtered, _ = extract_embeddings(\"Parque do Mindú/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=True)\n",
        "\n",
        "    np.save('MinduPark/MinduPark_vectors_filtered_'+str(i)+'.npy', MinduPark_vectors_filtered)\n",
        "\n",
        "!zip -r MinduPark.zip MinduPark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDr7cu5PwZLe"
      },
      "outputs": [],
      "source": [
        "!unzip -q Parque_do_Mindu_without_Sauim.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y9gEZjZwCde"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"MinduPark_without_sauim\", exist_ok=True)  # cria se não existir\n",
        "\n",
        "sr = 32000 # Sampling rate (Hz)\n",
        "window_len = int(5*sr) # 5-second window length in samples\n",
        "\n",
        "step = 2\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "for i, file in enumerate(os.listdir('Parque_do_Mindu_without_Sauim')):\n",
        "    MinduPark_vectors, _ = extract_embeddings(\"Parque_do_Mindu_without_Sauim/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=False)\n",
        "\n",
        "    np.save('MinduPark_without_sauim/MinduPark_vectors_'+str(i)+'.npy', MinduPark_vectors)\n",
        "\n",
        "    MinduPark_vectors_filtered, _ = extract_embeddings(\"Parque_do_Mindu_without_Sauim/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=True)\n",
        "\n",
        "    np.save('MinduPark_without_sauim/MinduPark_vectors_filtered_'+str(i)+'.npy', MinduPark_vectors_filtered)\n",
        "\n",
        "!zip -r MinduPark_without_sauim.zip MinduPark_without_sauim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRS40A3Fab7V"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"MinduPark_38\", exist_ok=True)  # cria se não existir\n",
        "\n",
        "step = 1\n",
        "hop_len = int(step*sr) # emulates an sliding window of 5 sec length and 1 sec step\n",
        "\n",
        "for i, file in enumerate(os.listdir('Parque_do_Mindu_38/Parque do Mindú')):\n",
        "    MinduPark_vectors, _ = extract_embeddings(\"Parque_do_Mindu_38/Parque do Mindú/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=False)\n",
        "\n",
        "    np.save('MinduPark_38/MinduPark_vectors_'+str(i)+'.npy', MinduPark_vectors)\n",
        "\n",
        "    MinduPark_vectors_filtered, _ = extract_embeddings(\"Parque_do_Mindu_38/Parque do Mindú/\"+file,\n",
        "                                                        wlen=window_len,\n",
        "                                                        hop_len=hop_len,\n",
        "                                                        bandpass_filter=True)\n",
        "\n",
        "    np.save('MinduPark_38/MinduPark_vectors_filtered_'+str(i)+'.npy', MinduPark_vectors_filtered)\n",
        "\n",
        "!zip -r MinduPark_38.zip MinduPark_38"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw6PIRa1i_71"
      },
      "source": [
        "Load labels, compute cosine distance matrix from embedding vectors, perform hierarchical clustering, and plot a dendrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP8Wp7qyumYH"
      },
      "outputs": [],
      "source": [
        "# 1. Load labels from CSV\n",
        "records = pd.read_csv('records.csv')  # adjust path if needed\n",
        "labels = records['Bosque_S.bicolor_12.4.19-000'].tolist()\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "encoded_labels = le.fit_transform(labels)\n",
        "\n",
        "# 2. Compute cosine distance matrix (condensed form)\n",
        "cosine_distances = pdist(sauim_vectors, metric='cosine')\n",
        "\n",
        "# 3. Perform hierarchical clustering\n",
        "Z = linkage(cosine_distances, method='ward')  # try 'ward', 'complete', etc.\n",
        "\n",
        "# 4. Plot dendrogram\n",
        "plt.figure(figsize=(20, 5))\n",
        "dendrogram(Z, labels=encoded_labels, leaf_font_size=10)\n",
        "plt.xlabel(\"Records segments with sauim vocalizations\")\n",
        "plt.ylabel(\"Cosine distances\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"dendongram.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGrT_E7C7z2b"
      },
      "outputs": [],
      "source": [
        "for i in zip(encoded_labels,labels):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h10EQFQsLdZ6"
      },
      "outputs": [],
      "source": [
        "# 1. Load labels from CSV\n",
        "records = pd.read_csv('records.csv')  # adjust path if needed\n",
        "labels = records['Bosque_S.bicolor_12.4.19-000'].tolist()\n",
        "\n",
        "# Encode labels as integers\n",
        "le = LabelEncoder()\n",
        "encoded_labels = le.fit_transform(labels)\n",
        "\n",
        "# 2. Compute cosine distance matrix (condensed form)\n",
        "cosine_distances = pdist(sauim_vectors_filtered, metric='cosine')\n",
        "\n",
        "# 3. Perform hierarchical clustering\n",
        "Z = linkage(cosine_distances, method='ward')  # try 'ward', 'complete', etc.\n",
        "\n",
        "# 4. Plot dendrogram\n",
        "plt.figure(figsize=(20, 5))\n",
        "dendrogram(Z, labels=encoded_labels, leaf_font_size=10)\n",
        "plt.xlabel(\"Records segments with sauim vocalizations\")\n",
        "plt.ylabel(\"Cosine distances\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"dendongram_filtered.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}